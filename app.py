# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1InRpdg8IzOVgP62tJ0yaTZRP_UpLnOZl
"""

# app.py
!pip install streamlit
import streamlit as st
from PIL import Image
import numpy as np
import tensorflow as tf
import json
import os
from io import BytesIO
import requests

st.set_page_config(page_title="Klasifikasi Kaktus", layout="centered")

# ---------- helper untuk load model dan labels (cached) ----------
@st.cache_resource
def load_model(model_path="model_kaktus.h5", labels_path="labels.json"):
    # jika model tidak ada di repo, kamu bisa ubah logika ini untuk download dari URL/cloud
    if not os.path.exists(model_path):
        st.warning("Model tidak ditemukan di repo. Jika model disimpan di cloud, cek app.py agar mendownload model saat startup.")
        raise FileNotFoundError(f"{model_path} tidak ditemukan.")
    model = tf.keras.models.load_model(model_path)
    with open(labels_path, "r") as f:
        labels = json.load(f)
    # labels: dict index->class_name (strings). Pastikan urutannya sesuai prediksi model (argmax)
    # ubah menjadi list berurut
    num_classes = len(labels)
    class_names = [labels[str(i)] if str(i) in labels else labels[i] for i in range(num_classes)]
    return model, class_names

# ---------- UI ----------
st.title("ðŸŒµ Klasifikasi Jenis Kaktus")
st.write("Upload foto kaktus, model akan menebak jenisnya.")

# sidebar info
st.sidebar.info("Upload foto JPG/PNG. Model di-load saat pertama kali app dijalankan.")

# file uploader
uploaded = st.file_uploader("Pilih gambar kaktus", type=["jpg","jpeg","png"])

# load model (tampilkan progress)
try:
    model, class_names = load_model()
except Exception as e:
    st.error(f"Gagal load model: {e}")
    st.stop()

IMAGE_SIZE = (150,150)  # sesuaikan dengan input modelmu

if uploaded:
    img = Image.open(uploaded).convert("RGB")
    st.image(img, caption="Gambar yang diupload", use_column_width=True)

    # preprocess sesuai saat training
    img_resized = img.resize(IMAGE_SIZE)
    img_arr = np.array(img_resized) / 255.0
    img_arr = np.expand_dims(img_arr, axis=0)  # batch dim

    # prediksi
    preds = model.predict(img_arr)
    pred_idx = int(np.argmax(preds, axis=1)[0])
    confidence = float(np.max(preds))
    pred_name = class_names[pred_idx] if pred_idx < len(class_names) else str(pred_idx)

    st.success(f"Prediksi: **{pred_name}**  â€” Confidence: {confidence:.2%}")

    # tampilkan kemungkinan lain (opsional)
    top_k = 5
    probs = preds[0]
    top_indices = probs.argsort()[-top_k:][::-1]
    st.write("Top predictions:")
    for i in top_indices:
        name = class_names[i] if i < len(class_names) else str(i)
        st.write(f"- {name}: {probs[i]:.2%}")